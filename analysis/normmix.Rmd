---
title: "EM vs. IP solution to mixture optimization problem"
author: "Peter Carbonetto"
date: August 9, 2017
output:
  html_document:
    theme: readable
    include:
      before_body: include/header.html
---

TO DO: Give overview of this analysis, and instructions for
experimenting with different analysis parameters.

```{r knitr, echo=FALSE}
knitr::opts_chunk$set(
  comment   = "#",
  results   = "hold",
  collapse  = TRUE,
  fig.align = "center",
  fig.path  = paste0("figure/", knitr::current_input(), "/"))
```

## Analysis setup

I begin by loading a few packages, as well as some additional
functions I wrote for this analysis.

```{r load-pkgs, message=FALSE}
library(Matrix)
library(ggplot2)
library(cowplot)
source("../code/datasim.R")
source("../code/likelihood.R")
source("../code/ipsolver.R")
source("../code/mixopt.R")
```

These variables determine how the data set is generated: the random
number generator seed, the number of data samples (n), the standard
errors of the samples (se), and the standard deviations (s) and
mixture weights (w) used to simulate the data.

Do not make the sample size (n) too large otherwise the interior-point
method will be very slow.

Also note that heterogeneous standard errors are allowed.

```{r data}
seed <- 1
n    <- 200
se   <- rep(0.1,n)
sim  <- list(s = c(0,   0.1, 0.2, 0.5),
             w = c(0.95,0.03,0.01,0.01))
```

Next, I specify the model parameters---specifically, the standard
deviations of the normal mixture components.

```{r model}
s <- c(0.01,10^(seq(-2,0,length.out = 39)))
```

## Generate data

Simulate a data set with n samples.

```{r sim-data}
cat(sprintf("Simulating data set with %d observations.\n",n))
set.seed(1)
k <- length(s)
x <- datasim.norm(sim$w,sim$s,se)
```

## Compute likelihood matrix

Compute the n x k conditional likelihood matrix.

```{r, calc-likelihood}
cat(sprintf("Computing the %d x %d conditional likelihood matrix.\n",n,k))
L <- condlikmatrix.norm(x,se,s)
```

## Fit mixture model using EM

First, fit the mixture model using the very simple EM algorithm.
Observe that individual EM iterations are fast but it takes many
iterations to converge to a solution.

```{r, em}
out <- system.time(fit.em <- mixopt.em(L,tol = 1e-4,verbose = FALSE))
cat(sprintf("Model fitting took %d iterations and %0.2f seconds.\n",
            length(fit.em$maxd),out["elapsed"]))
```

## Fit mixture model using IP method

The primal-dual interior-point solver is based on the algorithm
described by [Armand *et al*](https://doi.org/10.1137/S1052623498344720).
It is substantially more complicated than the EM algorithm, and
individual iterations are more expensive, but it takes only a small
number of iterations to converge to a solution.

```{r, ip}
out <- system.time(fit.ip <- mixopt.dualip(L))
cat(sprintf("Model fitting took %d iterations and %0.2f seconds.\n",
            length(fit.ip$maxd),out["elapsed"]))
```

Note that the EM algorithm implements a very simple convergence
criterion---the maximum difference between the iterates must be
small---whereas the convergence in the interior-point method is based
on how close we are to satisfying the KKT optimality conditions.

If you have the RMosek and REBayes packages installed, you can
compare the output of the IP method to running

```{r rebayes, echo=TRUE, eval=FALSE}
REBayes:KWDual(L,rep(1,k),rep(1,n))
```

```{r, include=FALSE}
# PLOT OPTIMIZATION RESULTS
# -------------------------
adjust.plot <- function (p)
  p + theme_cowplot(font_size = 9) +
    theme(plot.title = element_text(face = "plain"))

# Show the (maximum) change in the mixture weights vs. time running
# the EM algorithm.
m  <- length(fit.em$maxd)
i  <- 2:(m-1)
p1 <- ggplot(data.frame(time = fit.em$timing[i,"elapsed"],
                        maxd = fit.em$maxd[i]),
             aes(x = time,y = maxd)) +
  geom_line(col = "darkorange",size = 0.5) +
  geom_point(col = "darkorange",shape = 20) +
  scale_y_continuous(breaks = 10^seq(-4,-1),trans = "log10") +
  labs(x     = "elapsed time (seconds)",
       y     = "max. change in solution",
       title = "EM algorithm")

# Show the (maximum) change in the mixture weights vs. time running
# the interior-point method.
m  <- length(fit.ip$maxd)
i  <- 2:(m-1)
p2 <- ggplot(data.frame(time = fit.ip$timing[i,"elapsed"],
                        maxd = fit.ip$maxd[i]),
             aes(x = time,y = maxd)) +
  geom_line(col = "darkblue",size = 0.5) +
  geom_point(col = "darkblue",shape = 20) +
  scale_y_continuous(breaks = 10^(-3:1),trans = "log10") +
  labs(x     = "elapsed time (seconds)",
       y     = "max. change in solution",
       title = "IP algorithm")

# Show the value of the (primal) objective function vs. elapsed time
# running the EM algorithm.
m  <- length(fit.em$obj)
i  <- 2:(m-1)
p3 <- ggplot(data.frame(time = fit.em$timing[i,"elapsed"],
                        y    = fit.em$obj[i] - fit.ip$obj),
                        aes(x = time,y = y)) +
  geom_line(col = "darkorange",size = 0.5) +
  geom_point(col = "darkorange",shape = 20) +
  scale_y_continuous(breaks = 10^(-1:1),trans = "log10") +
  labs(x     = "elapsed time (seconds)",
       y     = "distance from primal min.",
       title = "EM algorithm")

# Show the value of the (dual) objective function vs. elapsed time
# running the interior-point method.
m  <- length(fit.ip$ipsolver$obj)
i  <- 2:(m-1)
p4 <- ggplot(data.frame(time = fit.ip$timing[i,"elapsed"],
                        y = fit.ip$ipsolver$obj[i] - min(fit.ip$ipsolver$obj)),
                        aes(x = time,y = y)) +
  geom_line(col = "darkorange",size = 0.5) +
  geom_point(col = "darkorange",shape = 20) +
  scale_y_continuous(breaks = 10^seq(-8,2,2),trans = "log10") +
  labs(x     = "elapsed time (seconds)",
       y     = "distance from dual min.",
       title = "IP algorithm")

# Draw all four plots.
print(plot_grid(adjust.plot(p1),adjust.plot(p3),
                adjust.plot(p2),adjust.plot(p4)))
```

## Session information

This is the version of R and the packages that were used to generate
these results.

```{r session-info}
sessionInfo()
```
